# -*- coding: utf-8 -*-
"""LGBM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FzSsNUgjdD5D7WteOSzP_VdPxIvtJtvi

### Loading data
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import xgboost as xgb
from xgboost import plot_importance, plot_tree
from sklearn.metrics import mean_squared_error, mean_absolute_error
plt.style.use('fivethirtyeight')
from typing import *
import os
import random
import datetime
import time
from lightgbm import LGBMRegressor

from sklearn.model_selection import train_test_split, GridSearchCV

market_data_files = [ 
    "market2_traders.csv",
]

columns = ['MidPriceETF', 'LastTradedPriceETF',
       'MidPriceFUT', 'LastTradedPriceFUT', 'ETF_BID_PRICE_0',
       'ETF_BID_PRICE_1', 'ETF_BID_PRICE_2', 'ETF_BID_PRICE_3',
       'ETF_BID_PRICE_4', 'ETF_BID_VOL_0', 'ETF_BID_VOL_1', 'ETF_BID_VOL_2',
       'ETF_BID_VOL_3', 'ETF_BID_VOL_4', 'ETF_ASK_PRICE_0', 'ETF_ASK_PRICE_1',
       'ETF_ASK_PRICE_2', 'ETF_ASK_PRICE_3', 'ETF_ASK_PRICE_4',
       'ETF_ASK_VOL_0', 'ETF_ASK_VOL_1', 'ETF_ASK_VOL_2', 'ETF_ASK_VOL_3',
       'ETF_ASK_VOL_4']

def load_market_data_files_to_df_list() -> List[pd.DataFrame]:
    all_dfs = []
    
    for market_file_name in market_data_files:
        # we make sure that we're only reading rows where the last traded prices aren't 0
        df = pd.read_csv(market_file_name, index_col="Index").iloc[30:].drop(columns=["Unnamed: 0", "Time"])
        df.index = df.index.astype(int)
        for column in df.columns:
            if "VOL" not in column:
              df[column] = df[column] / 100
            else:
              df[column] = df[column].astype(int)
            assert df[column].isnull().values.any() == False
        assert len(df[df["LastTradedPriceETF"] == 0]) == 0
        assert len(df[df["LastTradedPriceFUT"] == 0]) == 0
        all_dfs.append(df)
    
    return all_dfs

df = load_market_data_files_to_df_list()[0]

df.head()

"""## First attempt

### Feature engineering

#### Parameters
"""

lag_window = 20
target_ahead = 3

"""#### Creating training data"""

def create_features(df) -> pd.DataFrame:
    new_df = df.copy()
    for lag in range(lag_window + 1):
        for column in df.columns:
            new_df[f'{column}_{lag}'] = df[column].shift(lag)
    new_df["target"] = df["MidPriceETF"].shift(3)
    new_df = new_df.drop(columns=df.columns)
    new_df = new_df.iloc[lag_window+1:-3]
    for column in new_df.columns:
      assert new_df[column].isnull().values.any() == False
    return new_df

data = create_features(df)

data.head()

test_size  = 0.15
valid_size = 0.15

test_split_idx  = int(data.shape[0] * (1-test_size))
valid_split_idx = int(data.shape[0] * (1-(valid_size+test_size)))

train_data  = data.loc[:valid_split_idx].copy()
valid_data  = data.loc[valid_split_idx+1:test_split_idx].copy()
test_data   = data.loc[test_split_idx+1:].copy()

y_train = train_data['target'].copy()
X_train = train_data.drop(['target'], 1)

y_valid = valid_data['target'].copy()
X_valid = valid_data.drop(['target'], 1)

y_test  = test_data['target'].copy()
X_test  = test_data.drop(['target'], 1)

"""### Creating the model and training"""

parameters = {
    'n_estimators': [100, 200, 300, 400],
    'learning_rate': [0.001, 0.005, 0.01, 0.05],
    'max_depth': [8, 10, 12, 15],
    'gamma': [0.001, 0.005, 0.01, 0.02],
    'random_state': [42]
}

model = LGBMRegressor(n_estimators=10)
model.fit(X_train, y_train)

"""#### Embargo Cross-Validation"""

# this function prevents leakage of data into other splits, not within split...
# Adapted from numerai tournament
def get_time_series_cross_val_splits(data, cv = 5, embargo = 3750):
    all_train_timestamps = data['timestamp'].unique()
    len_split = len(all_train_timestamps) // cv
    test_splits = [all_train_timestamps[i * len_split:(i + 1) * len_split] for i in range(cv)]
    # fix the last test split to have all the last timestamps, in case the number of timestamps wasn't divisible by cv
    rem = len(all_train_timestamps) - len_split*cv
    if rem>0:
        test_splits[-1] = np.append(test_splits[-1], all_train_timestamps[-rem:])

    train_splits = []
    for test_split in test_splits:
        test_split_max = int(np.max(test_split))
        test_split_min = int(np.min(test_split))
        # get all of the timestamps that aren't in the test split
        train_split_not_embargoed = [e for e in all_train_timestamps if not (test_split_min <= int(e) <= test_split_max)]
        # embargo the train split so we have no leakage. Note timestamps are expressed in seconds, so multiply by 60
        embargo_sec = 60*embargo
        train_split = [e for e in train_split_not_embargoed if
                       abs(int(e) - test_split_max) > embargo_sec and abs(int(e) - test_split_min) > embargo_sec]
        train_splits.append(train_split)

    # convenient way to iterate over train and test splits
    train_test_zip = zip(train_splits, test_splits)
    return train_test_zip

"""### Checking out how the model does"""

pred_array = model.predict(X=X_test.iloc[:10])

pred = pd.Series(pred_array, index=y_test[:10].index)

pred.plot()
y_test[:10].plot()

"""## Second attempt (less and better features)"""

lag_window = 20 
target_ahead = 1

"""Now we're just gonna use the ETF and FUT midprices and the target is the log return one step ahead"""

def log_return(series, periods=1):
  return np.log(series).diff(periods=periods)

"""#### How the G-research winner does it"""

def get_features(df, train=True):   
    if train == True:
        totimestamp = lambda s: np.int32(time.mktime(datetime.datetime.strptime(s, "%d/%m/%Y").timetuple()))
        valid_window = [totimestamp("12/03/2021")]
#         valid_window = [totimestamp("15/08/2021")]  #検証用
        df['train_flg'] = np.where(df['timestamp']>=valid_window[0], 0,1)

        supple_start_window = [totimestamp("22/09/2021")]
        if use_supple_for_train:
            df['train_flg'] = np.where(df['timestamp']>=supple_start_window[0], 1 ,df['train_flg']  )

   
    for id in range(14):    
        for lag in lags:
            df[f'log_close/mean_{lag}_id{id}'] = np.log( np.array(df[f'Close_{id}']) /  np.roll(np.append(np.convolve( np.array(df[f'Close_{id}']), np.ones(lag)/lag, mode="valid"), np.ones(lag-1)), lag-1)  )
            df[f'log_return_{lag}_id{id}']     = np.log( np.array(df[f'Close_{id}']) /  np.roll(np.array(df[f'Close_{id}']), lag)  )
    for lag in lags:
        df[f'mean_close/mean_{lag}'] =  np.mean(df.iloc[:,df.columns.str.startswith(f'log_close/mean_{lag}_id')], axis=1)
        df[f'mean_log_returns_{lag}'] = np.mean(df.iloc[:,df.columns.str.startswith(f'log_return_{lag}_id')] ,    axis=1)
        for id in range(14):
            df[f'log_close/mean_{lag}-mean_close/mean_{lag}_id{id}'] = np.array( df[f'log_close/mean_{lag}_id{id}']) - np.array( df[f'mean_close/mean_{lag}']  )
            df[f'log_return_{lag}-mean_log_returns_{lag}_id{id}']    = np.array( df[f'log_return_{lag}_id{id}'])     - np.array( df[f'mean_log_returns_{lag}'] )

    if train == True:
        for id in range(14):
            df = df.drop([f'Close_{id}'], axis=1)
        oldest_use_window = [totimestamp("12/01/2019")]
        df = df[  df['timestamp'] >= oldest_use_window[0]   ]

    return df

"""$$log(close/mean)_{lag} = log(\frac{close_i}{mean(close_{i-1}, \dots, close_{i-lag})})$$

---

#### How we do it
"""

df.head()

def get_features_2(df) -> pd.DataFrame:
    # print(df.head())
    new_df = df.copy()
    for lag in range(1, lag_window + 1):
      new_df[f'log_etf/etf_mean_{lag}'] = np.log( np.array(df['MidPriceETF']) / np.roll( np.append( np.convolve( np.array(df['MidPriceETF']), np.ones(lag)/lag , mode="valid"), np.ones(lag-1) ), lag) ) 
      new_df[f'log_fut/fut_mean_{lag}'] = np.log( np.array(df['MidPriceFUT']) / np.roll( np.append( np.convolve( np.array(df['MidPriceFUT']), np.ones(lag)/lag , mode="valid"), np.ones(lag-1) ), lag) ) 
      new_df[f'log_diff/diff_mean_{lag}'] = np.log( (np.array(df['MidPriceETF'])/np.array(df['MidPriceFUT'])) / np.roll( np.append( np.convolve( (np.array(df['MidPriceETF'])/np.array(df['MidPriceFUT'])), np.ones(lag)/lag, mode="valid"), np.ones(lag-1) ), lag) )
      new_df[f'log_etf_return_{lag}'] = np.log( np.array(df["MidPriceETF"]) / np.roll(np.array(df["MidPriceETF"]), lag) )
      new_df[f'log_fut_return_{lag}'] = np.log( np.array(df["MidPriceFUT"]) / np.roll(np.array(df["MidPriceFUT"]), lag) )
    new_df["target"] = np.log( np.roll(np.array(df['MidPriceETF']), -target_ahead) / np.array(df["MidPriceETF"]) ) 
    new_df = new_df.drop(columns=df.columns)
    new_df["MidPriceETF"] = df["MidPriceETF"]
    new_df["MidPriceFUT"] = df["MidPriceFUT"]
    new_df = new_df.iloc[lag_window:-target_ahead]
    for column in new_df.columns:
      assert new_df[column].isnull().values.any() == False
    return new_df

proc_data = get_features_2(df)

proc_data.head()

def verify_features_2(data, proc_data) -> None:
  etf_midprice = np.array( data["MidPriceETF"] ) # .iloc[lag_window+1:-target_ahead] )
  fut_midprice = np.array( data["MidPriceFUT"] ) # .iloc[lag_window+1:-target_ahead] )
  for lag in range(1, lag_window + 1):
    # Column 1
    other_log_etf_over_mean_price = np.array( proc_data[f'log_etf/etf_mean_{lag}'] )
    # Column 3 
    other_log_diff_over_diff_mean = np.array( proc_data[f'log_diff/diff_mean_{lag}'] )
    # Target
    other_target = np.array( proc_data['target'] )

    for i in range(lag_window, len(etf_midprice) - target_ahead):
      other_i = i - lag_window # indices are shifted in the proc_data by lag_window

      # Check Column 1
      mean_etf_midprice = 0.0
      for j in range(1, lag + 1):
        assert i - j >= 0
        mean_etf_midprice += etf_midprice[i - j] / lag
      log_etf_over_mean_price = np.log(etf_midprice[i] / mean_etf_midprice)
      if abs(log_etf_over_mean_price - other_log_etf_over_mean_price[other_i]) > 1e-8:
        print("i={0}, lag={1}, other_calc={2}, now_calc={3}".format(i, lag, other_log_etf_over_mean_price[other_i], log_etf_over_mean_price))
        print(etf_midprice[i - lag : i + 1])
      assert abs(other_log_etf_over_mean_price[other_i] - log_etf_over_mean_price) < 1e-8

      # Check Column 3 
      diff_mean = 0.0
      for j in range(1, lag + 1):
        diff_mean += (etf_midprice[i - j] / fut_midprice[i - j]) / lag
      log_diff_over_diff_mean = np.log( (etf_midprice[i] / fut_midprice[i]) / diff_mean )
      if abs(log_diff_over_diff_mean - other_log_diff_over_diff_mean[other_i]) > 1e-8:
        print("i={0}, lag={1}, other_calc={2}, now_calc={3}".format(i, lag, other_log_etf_over_mean_price[other_i], log_etf_over_mean_price))
        print(etf_midprice[i - lag : i + 1])
        print(fut_midprice[i - lag : i + 1])
      assert abs(log_diff_over_diff_mean - other_log_diff_over_diff_mean[other_i]) < 1e-8
       
      # Check target
      target = np.log( etf_prices[i + target_ahead] / etf_prices[i] )
      if abs(target - other_target[other_i]) > 1e-6:
        print(i, lag)
        print(target)
        print(other_target[other_i])
        print(etf_prices[i + target_ahead], etf_prices[i])
      assert abs(target - other_target[other_i]) < 1e-6

"""We now verify that the features have been calculated correctly"""

verify_features_2(df, proc_data)

"""### Creating the model and training"""

seed0 = 42

params = {
    'early_stopping_rounds': 50,
    'objective': 'regression',
    'metric': 'rmse',
#     'metric': 'None',
    'boosting_type': 'gbdt',
    'max_depth': 5,
    'verbose': -1,
    'max_bin':600,
    'min_data_in_leaf':50,
    'learning_rate': 0.03,
    'subsample': 0.7,
    'subsample_freq': 1,
    'feature_fraction': 1,
    'lambda_l1': 0.5,
    'lambda_l2': 2,
    'seed':seed0,
    'feature_fraction_seed': seed0,
    'bagging_fraction_seed': seed0,
    'drop_seed': seed0,
    'data_random_seed': seed0,
    'extra_trees': True,
    'extra_seed': seed0,
    'zero_as_missing': True,
    "first_metric_only": True
}

test_size  = 0.15
valid_size = 0.15

test_split_idx  = int(proc_data.shape[0] * (1-test_size))
valid_split_idx = int(proc_data.shape[0] * (1-(valid_size+test_size)))

train_data  = proc_data.loc[:valid_split_idx].copy()
valid_data  = proc_data.loc[valid_split_idx+1:test_split_idx].copy()
test_data   = proc_data.loc[test_split_idx+1:].copy()

y_train = train_data['target'].copy() * 1000
X_train = train_data.drop(['target', "MidPriceETF", "MidPriceFUT"], 1) * 1000

y_valid = valid_data['target'].copy() * 1000
X_valid = valid_data.drop(['target', "MidPriceETF", "MidPriceFUT"], 1) * 1000

y_test  = test_data['target'].copy() * 1000
X_test  = test_data.drop(['target', "MidPriceETF", "MidPriceFUT"], 1) * 1000

X_train.head()

"""### Creating the model"""

features = list(X_train.columns)
not_used_features_train = ['target', "MidPriceETF", "MidPriceFUT"]

n_fold = 7

"""#### Functions used by G-Research solution"""

# define the evaluation metric
def correlation(a, train_data):
    
    b = train_data.get_label()
    
    a = np.ravel(a)
    b = np.ravel(b)

    len_data = len(a)
    mean_a = np.sum(a) / len_data
    mean_b = np.sum(b) / len_data
    var_a = np.sum(np.square(a - mean_a)) / len_data
    var_b = np.sum(np.square(b - mean_b)) / len_data

    cov = np.sum((a * b))/len_data - mean_a*mean_b
    corr = cov / np.sqrt(var_a * var_b)

    return 'corr', corr, True

# For CV score calculation
def corr_score(pred, valid):
    len_data = len(pred)
    mean_pred = np.sum(pred) / len_data
    mean_valid = np.sum(valid) / len_data
    var_pred = np.sum(np.square(pred - mean_pred)) / len_data
    var_valid = np.sum(np.square(valid - mean_valid)) / len_data

    cov = np.sum((pred * valid))/len_data - mean_pred*mean_valid
    corr = cov / np.sqrt(var_pred * var_valid)

    return corr

# For CV score calculation
def wcorr_score(pred, valid, weight):
    len_data = len(pred)
    sum_w = np.sum(weight)
    mean_pred = np.sum(pred * weight) / sum_w
    mean_valid = np.sum(valid * weight) / sum_w
    var_pred = np.sum(weight * np.square(pred - mean_pred)) / sum_w
    var_valid = np.sum(weight * np.square(valid - mean_valid)) / sum_w

    cov = np.sum((pred * valid * weight)) / sum_w - mean_pred*mean_valid
    corr = cov / np.sqrt(var_pred * var_valid)

    return corr

# from: https://blog.amedama.jp/entry/lightgbm-cv-feature-importance
# (used in nyanp's Optiver solution)
def plot_importance(importances, features_names = features, PLOT_TOP_N = 20, figsize=(10, 10)):
    importance_df = pd.DataFrame(data=importances, columns=features)
    sorted_indices = importance_df.median(axis=0).sort_values(ascending=False).index
    sorted_importance_df = importance_df.loc[:, sorted_indices]
    plot_cols = sorted_importance_df.columns[:PLOT_TOP_N]
    _, ax = plt.subplots(figsize=figsize)
    ax.grid()
    ax.set_xscale('log')
    ax.set_ylabel('Feature')
    ax.set_xlabel('Importance')
    sns.boxplot(data=sorted_importance_df[plot_cols],
                orient='h',
                ax=ax)
    plt.show()

# from: https://www.kaggle.com/code/nrcjea001/lgbm-embargocv-weightedpearson-lagtarget/
def get_time_series_cross_val_splits(data, cv = n_fold, embargo = 3750):
    all_train_timestamps = data['timestamp'].unique()
    len_split = len(all_train_timestamps) // cv
    test_splits = [all_train_timestamps[i * len_split:(i + 1) * len_split] for i in range(cv)]
    # fix the last test split to have all the last timestamps, in case the number of timestamps wasn't divisible by cv
    rem = len(all_train_timestamps) - len_split*cv
    if rem>0:
        test_splits[-1] = np.append(test_splits[-1], all_train_timestamps[-rem:])

    train_splits = []
    for test_split in test_splits:
        test_split_max = int(np.max(test_split))
        test_split_min = int(np.min(test_split))
        # get all of the timestamps that aren't in the test split
        train_split_not_embargoed = [e for e in all_train_timestamps if not (test_split_min <= int(e) <= test_split_max)]
        # embargo the train split so we have no leakage. Note timestamps are expressed in seconds, so multiply by 60
        embargo_sec = 60*embargo
        train_split = [e for e in train_split_not_embargoed if
                       abs(int(e) - test_split_max) > embargo_sec and abs(int(e) - test_split_min) > embargo_sec]
        train_splits.append(train_split)

    # convenient way to iterate over train and test splits
    train_test_zip = zip(train_splits, test_splits)
    return train_test_zip

import lightgbm as lgb
import time
import datetime

import pickle
import gc

from tqdm import tqdm

def get_Xy_and_model_for_asset(df_proc, asset_id):
    df_proc = df_proc.loc[  (df_proc[f'Target_{asset_id}'] == df_proc[f'Target_{asset_id}'])  ]
    if not_use_overlap_to_train:
        df_proc = df_proc.loc[  (df_proc['train_flg'] == 1)  ]
    
    # EmbargoCV
    train_test_zip = get_time_series_cross_val_splits(df_proc, cv = n_fold, embargo = 3750)
    print("entering time series cross validation loop")
    importances = []
    oof_pred = []
    oof_valid = []
    
    for split, train_test_split in enumerate(train_test_zip):
        gc.collect()
        
        print(f"doing split {split+1} out of {n_fold}")
        train_split, test_split = train_test_split
        train_split_index = df_proc['timestamp'].isin(train_split)
        test_split_index = df_proc['timestamp'].isin(test_split)
    
        train_dataset = lgb.Dataset(df_proc.loc[train_split_index, features],
                                    df_proc.loc[train_split_index, f'Target_{asset_id}'].values, 
                                    feature_name = features, 
                                   )
        val_dataset = lgb.Dataset(df_proc.loc[test_split_index, features], 
                                  df_proc.loc[test_split_index, f'Target_{asset_id}'].values, 
                                  feature_name = features, 
                                 )

        print(f"number of train data: {len(df_proc.loc[train_split_index])}")
        print(f"number of val data:   {len(df_proc.loc[test_split_index])}")

        model = lgb.train(params = params,
                          train_set = train_dataset, 
                          valid_sets=[train_dataset, val_dataset],
                          valid_names=['tr', 'vl'],
                          num_boost_round = 5000,
                          verbose_eval = 100,     
                          feval = correlation,
                         )
        importances.append(model.feature_importance(importance_type='gain'))
        
        file = f'trained_model_id{asset_id}_fold{split}.pkl'
        pickle.dump(model, open(file, 'wb'))
        print(f"Trained model was saved to 'trained_model_id{asset_id}_fold{split}.pkl'")
        print("")
            
        oof_pred += list(  model.predict(df_proc.loc[test_split_index, features])        )
        oof_valid += list(   df_proc.loc[test_split_index, f'Target_{asset_id}'].values    )
    
    
    plot_importance(np.array(importances),features, PLOT_TOP_N = 20, figsize=(10, 5))

    return oof_pred, oof_valid

"""#### Our model

##### For now let's just train one without CV or anything
"""

X_train.head()

y_train

train_dataset = lgb.Dataset(X_train,
                            y_train,
                            feature_name = features)

val_dataset = lgb.Dataset(X_test,
                          y_test,
                          feature_name = features)

model = lgb.train(params = params,
                  train_set = train_dataset, 
                  valid_sets=[train_dataset, val_dataset],
                  valid_names=['tr', 'vl'],
                  num_boost_round = 5000,
                  verbose_eval = 100,
                  feval = correlation)

# file = f'second_trained_model.pkl'
# pickle.dump(model, open(file, 'wb'))
# print(f"Trained model was saved to 'second_trained_model.pkl'")

"""##### Let's check out the model performance"""

pred = list(model.predict(test_data.drop(columns=not_used_features_train)))

plt.plot(pred)

"""##### Let's try to visualize the price predictions of the model"""

# we're gonna take the first 50 ticks of the test data
plt.plot(pred[:50])

price_pred = np.zeros(50 + target_ahead)
for i in range(50):
    log_return_pred = pred[i]
    etf_midprice = test_data.iloc[i]["MidPriceETF"]
    fut_midprice = test_data.iloc[i]["MidPriceFUT"]
    etf_price_prediction = np.exp(log_return_pred) * etf_midprice
    price_pred[i + target_ahead] = etf_price_prediction

price_pred = price_pred[target_ahead:]
actual_prices = list(test_data["MidPriceETF"].iloc[target_ahead:50 + target_ahead])

# plt.plot(price_pred, label="prediction")
plt.plot(actual_prices, label="actual")
plt.legend()

"""##### More complicated training function:"""

def get_Xy_and_model(df_proc):
    
    # EmbargoCV
    train_test_zip = get_time_series_cross_val_splits(df_proc, cv = n_fold, embargo = 3750)
    print("entering time series cross validation loop")
    importances = []
    oof_pred = []
    oof_valid = []
    
    for split, train_test_split in enumerate(train_test_zip):
        gc.collect()
        
        print(f"doing split {split+1} out of {n_fold}")
        train_split, test_split = train_test_split
        train_split_index = df_proc['timestamp'].isin(train_split)
        test_split_index = df_proc['timestamp'].isin(test_split)
    
        train_dataset = lgb.Dataset(df_proc.loc[train_split_index, features],
                                    df_proc.loc[train_split_index, f'Target_{asset_id}'].values, 
                                    feature_name = features, 
                                   )
        val_dataset = lgb.Dataset(df_proc.loc[test_split_index, features], 
                                  df_proc.loc[test_split_index, f'Target_{asset_id}'].values, 
                                  feature_name = features, 
                                 )

        print(f"number of train data: {len(df_proc.loc[train_split_index])}")
        print(f"number of val data:   {len(df_proc.loc[test_split_index])}")

        model = lgb.train(params = params,
                          train_set = train_dataset, 
                          valid_sets=[train_dataset, val_dataset],
                          valid_names=['tr', 'vl'],
                          num_boost_round = 5000,
                          verbose_eval = 100,     
                          feval = correlation,
                         )
        importances.append(model.feature_importance(importance_type='gain'))
        
        file = f'trained_model_id{asset_id}_fold{split}.pkl'
        pickle.dump(model, open(file, 'wb'))
        print(f"Trained model was saved to 'trained_model_id{asset_id}_fold{split}.pkl'")
        print("")
            
        oof_pred += list(  model.predict(df_proc.loc[test_split_index, features])        )
        oof_valid += list(   df_proc.loc[test_split_index, f'Target_{asset_id}'].values    )
    
    
    plot_importance(np.array(importances),features, PLOT_TOP_N = 20, figsize=(10, 5))

    return oof_pred, oof_valid



"""## Third Attempt

At least now we have a model that doesn't make constant predictions. Let's put all the pipeline into *just* one function so we can quickly change parameters
"""

